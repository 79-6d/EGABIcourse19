[
["index.html", "SCAR-EGABI Tools for Southern Ocean Spatial Analysis and Modelling 1 About this Technical stuff", " SCAR-EGABI Tools for Southern Ocean Spatial Analysis and Modelling Anton Van de Putte, Charlène Guillaumot, Grant Humphries, Huw Griffith, Ben Raymond 1 About this This document provides material for the SCAR-EGABI Tools for Southern Ocean Spatial Analysis and Modelling Course to be held in Leuven, Belgium in September 2019. Issues or suggestions about the content can be raised through the issue tracker (GitHub account required). Technical stuff This material has been written using bookdown and R. To build the book locally, clone the repo, open R and run the following lines: setwd(&quot;the/path/to/your/copy/of/the/repo&quot;) bookdown::render_book(&quot;index.Rmd&quot;) And view it with: browseURL(&quot;docs/index.html&quot;) "],
["preliminary-course-schedule.html", "2 Preliminary course schedule 2.1 Monday 2.2 Tuesday 2.3 Wednesday 2.4 Thursday 2.5 Friday", " 2 Preliminary course schedule 2.1 Monday Time Item 9:00 Course introduction, Housekeeping, presentation of participants 10:00 Coffee Break 10:15 Introduction to R and the Tidyverse 11:15 Break 11:30 Datacleaning, student feedback 12:30 Lunch 13:00 Finding and downloading data through the rOpenSci packages 14:00 Coffee Break 14:15 Mapping - the special case of Antarctica and polar projections 15:15 Break 15:30 Data visualisation 17:30 End day 1 2.2 Tuesday Time Item 9:00 What is SDM? 10:00 Coffee Break 10:15 Historic of application of SDMs 11:15 Break 11:30 Different algorithms 12:30 Lunch 13:00 other modelling approaches 14:00 Coffee Break 14:15 SDM calibration: occurrence data cleaning 15:15 Break 15:30 SDM calibration: choosing environmental layers 16:30 SDM calibration: pseudo-absences sampling 17:30 End day 2 2.3 Wednesday Time Item 9:00 SDM validation 10:00 Coffee Break 10:15 SDM outputs 11:15 Break 11:30 SDM outputs 12:30 Lunch 13:00 SDMs applied in the Southern Ocean 14:00 Coffee Break 14:15 SDMs applied in the Southern Ocean 15:15 Break 15:30 Judge your SDM results 16:30 Judge your SDM results 17:30 End day 3 2.4 Thursday Time Item 9:00 Personal Work 10:00 Coffee Break 10:30 Personal Work 12:30 Lunch 13:00 Personal Work 14:00 Coffee Break 14:30 Personal Work 17:30 End Day 4 2.5 Friday Time Item 9:00 Personal Work 10:00 Coffee Break 10:30 Personal Work 12:30 Lunch 13:00 Final Presentations 14:00 Coffee Break 14:30 Final Presentations 17:30 End Day 5 "],
["overview.html", "3 Overview 3.1 Preparation 3.2 Taxonomy 3.3 Occurrences 3.4 Environmental data 3.5 Fit model 3.6 Predict from model 3.7 Other bits and pieces", " 3 Overview An example analysis that very briefly demonstrates some of the tasks that we’ll tackle during the workshop. 3.1 Preparation Make sure we have the packages we need from CRAN: pkgs &lt;- c(&quot;dplyr&quot;, &quot;ncdf4&quot;, &quot;raster&quot;, &quot;remotes&quot;, &quot;robis&quot;, &quot;worrms&quot;) pkgs &lt;- setdiff(pkgs, installed.packages()[, 1]) if (length(pkgs) &gt; 0) install.packages(pkgs) library(dplyr) ## Warning: package &#39;dplyr&#39; was built under R version 3.4.4 And from GitHub: ## packages with required minimum version pkgs &lt;- c(&quot;SCAR/antanym&quot; = NA, &quot;AustralianAntarcticDivision/blueant&quot; = NA, &quot;AustralianAntarcticDivision/SOmap&quot; = &quot;0.3.0&quot;) for (pkg in names(pkgs)) { if (!basename(pkg) %in% installed.packages()[, 1] || (!is.na(pkgs[[pkg]]) &amp;&amp; packageVersion(basename(pkg)) &lt; pkgs[[pkg]])) { remotes::install_github(pkg) } } 3.2 Taxonomy library(worrms) my_species &lt;- &quot;Euphausia crystallorophias&quot; tax &lt;- wm_records_names(name = my_species) tax ## [[1]] ## # A tibble: 1 x 27 ## AphiaID url ## &lt;int&gt; &lt;chr&gt; ## 1 236216 http://www.marinespecies.org/aphia.php?p=taxdetails&amp;id=236216 ## scientificname authority status ## &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; ## 1 Euphausia crystallorophias Holt &amp; Tattersall, 1906 accepted ## unacceptreason taxonRankID rank valid_AphiaID ## &lt;lgl&gt; &lt;int&gt; &lt;chr&gt; &lt;int&gt; ## 1 NA 220 Species 236216 ## valid_name valid_authority parentNameUsageID ## &lt;chr&gt; &lt;chr&gt; &lt;int&gt; ## 1 Euphausia crystallorophias Holt &amp; Tattersall, 1906 110673 ## kingdom phylum class order family genus ## &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; ## 1 Animalia Arthropoda Malacostraca Euphausiacea Euphausiidae Euphausia ## citation ## &lt;chr&gt; ## 1 Siegel, V. (Ed) (2019). World Euphausiacea Database. Euphausia crystallo~ ## lsid isMarine isBrackish ## &lt;chr&gt; &lt;int&gt; &lt;lgl&gt; ## 1 urn:lsid:marinespecies.org:taxname:236216 1 NA ## isFreshwater isTerrestrial isExtinct match_type modified ## &lt;lgl&gt; &lt;lgl&gt; &lt;lgl&gt; &lt;chr&gt; &lt;chr&gt; ## 1 NA NA NA exact 2010-03-02T17:11:18.233Z ## the Aphia ID (taxonomic ID) of our species my_aphia_id &lt;- tax[[1]]$valid_AphiaID 3.3 Occurrences Get all data from the Antarctic Euphausiacea occurence data from “German Antarctic Marine Living Resources” (GAMLR) Expeditions data set: library(robis) ## Warning: package &#39;robis&#39; was built under R version 3.4.4 ##ds &lt;- dataset(taxonid = my_aphia_id) ##x &lt;- occurrence(datasetid = ds$id[6]) x &lt;- occurrence(datasetid = &quot;cb16377b-56a8-4d95-802d-4eec02466773&quot;) Plot the complete distribution of samples in black, and Euphausia crystallorophias in green: library(SOmap) ## Warning: package &#39;raster&#39; was built under R version 3.4.4 ## Warning: package &#39;sp&#39; was built under R version 3.4.4 SOmap_auto(x$decimalLongitude, x$decimalLatitude, input_lines = FALSE, pcol = &quot;black&quot;, pcex = 0.2) with(x %&gt;% dplyr::filter(aphiaID == my_aphia_id), SOplot(decimalLongitude, decimalLatitude, pch = 19, cex = 0.2, col = &quot;green&quot;)) Or as a polar stereo map: basemap &lt;- SOmap(trim = ceiling(max(x$decimalLatitude))+1, bathy_legend = FALSE) plot(basemap) SOplot(x$decimalLongitude, x$decimalLatitude, pch = 19, cex = 0.2, col = &quot;black&quot;) with(x %&gt;% dplyr::filter(aphiaID == my_aphia_id), SOplot(decimalLongitude, decimalLatitude, pch = 19, cex = 0.2, col = &quot;green&quot;)) Reorganise data into presence/absence by sampling site: xfit &lt;- x %&gt;% dplyr::rename(lon = &quot;decimalLongitude&quot;, lat = &quot;decimalLatitude&quot;) %&gt;% group_by(lon, lat) %&gt;% dplyr::summarize(present = any(my_aphia_id %in% aphiaID)) 3.4 Environmental data library(blueant) ## put the data into a temporary directory my_data_directory &lt;- tempdir() ## the data source we want data_source &lt;- sources_sdm(&quot;Southern Ocean marine environmental data&quot;) ## fetch the data status &lt;- bb_get(data_source, local_file_root = my_data_directory, verbose = TRUE) ## ## Mon Jul 29 17:20:07 2019 ## Synchronizing dataset: Southern Ocean marine environmental data ## Source URL https://data.aad.gov.au/eds/4742/download ## -------------------------------------------------------------------------------------------- ## ## this dataset path is: C:\\Users\\ben_ray\\AppData\\Local\\Temp\\RtmpELLr7i/data.aad.gov.au/eds/4742 ## building file list ... done. ## downloading file 1 of 1: https://data.aad.gov.au/eds/4742/download ... done. ## decompressing: C:\\Users\\ben_ray\\AppData\\Local\\Temp\\RtmpELLr7i/data.aad.gov.au/eds/4742/download.zip ... extracting 60 files into C:/Users/ben_ray/AppData/Local/Temp/RtmpELLr7i/data.aad.gov.au/eds/4742 ... done. ## ## Mon Jul 29 17:20:23 2019 dataset synchronization complete: Southern Ocean marine environmental data nc_files &lt;- Filter(function(z) grepl(&quot;\\\\.nc$&quot;, z), status$files[[1]]$file) ## create a raster stack of all layers env_stack &lt;- stack(nc_files) ## the first few layers head(names(env_stack)) ## [1] &quot;chla_ampli_alltime_2005_2012&quot; &quot;chla_max_alltime_2005_2012&quot; ## [3] &quot;chla_mean_alltime_2005_2012&quot; &quot;chla_min_alltime_2005_2012&quot; ## [5] &quot;chla_sd_alltime_2005_2012&quot; &quot;depth&quot; Select just the depth and ice_cover_mean layers and extract their values at our sampling locations: env_stack &lt;- subset(env_stack, c(&quot;depth&quot;, &quot;ice_cover_mean&quot;)) temp &lt;- as.data.frame(raster::extract(env_stack, xfit[, c(&quot;lon&quot;, &quot;lat&quot;)])) xfit &lt;- bind_cols(xfit, temp) head(xfit) ## # A tibble: 6 x 5 ## # Groups: lon [5] ## lon lat present depth ice_cover_mean ## &lt;dbl&gt; &lt;dbl&gt; &lt;lgl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 -122. -73.2 TRUE -660. 0.730 ## 2 -122. -73.2 FALSE -660. 0.730 ## 3 -121. -72.6 FALSE -1409. 0.747 ## 4 -121. -72.6 FALSE -1409. 0.747 ## 5 -121. -72.1 FALSE -1764. 0.726 ## 6 -121. -72.1 FALSE -1764. 0.726 3.5 Fit model We have presence/absence data, so we’ll fit a simple binomial model. The probability of presence of Euphausia crystallorophias is fitted as a smooth function of depth and mean sea ice cover: library(mgcv) ## Warning: package &#39;mgcv&#39; was built under R version 3.4.4 fit &lt;- gam(present ~ s(depth) + s(ice_cover_mean), family = binomial, data = xfit) summary(fit) ## ## Family: binomial ## Link function: logit ## ## Formula: ## present ~ s(depth) + s(ice_cover_mean) ## ## Parametric coefficients: ## Estimate Std. Error z value Pr(&gt;|z|) ## (Intercept) -4.3728 0.3402 -12.85 &lt;2e-16 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Approximate significance of smooth terms: ## edf Ref.df Chi.sq p-value ## s(depth) 3.029 3.792 42.03 2.33e-08 *** ## s(ice_cover_mean) 8.501 8.923 206.88 &lt; 2e-16 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## R-sq.(adj) = 0.265 Deviance explained = 32.5% ## UBRE = -0.64176 Scale est. = 1 n = 2390 The fits to depth and ice cover: plot(fit, pages = 1, shade = TRUE) 3.6 Predict from model xpred &lt;- expand.grid(lon = seq(from = floor(min(xfit$lon)), to = ceiling(max(xfit$lon)), by = 0.25), lat = seq(from = floor(min(xfit$lat)), to = ceiling(max(xfit$lat)), by = 0.25)) xpred &lt;- bind_cols(as.data.frame(xpred), as.data.frame(raster::extract(env_stack, xpred[, c(&quot;lon&quot;, &quot;lat&quot;)]))) xpred$predicted &lt;- predict(fit, newdata = xpred, type = &quot;response&quot;) ## create raster pr &lt;- rasterFromXYZ(xpred[, c(&quot;lon&quot;, &quot;lat&quot;, &quot;predicted&quot;)]) projection(pr) &lt;- &quot;+proj=longlat +datum=WGS84&quot; my_cmap &lt;- if (getRversion() &gt;= &quot;3.6&quot;) hcl.colors(21, &quot;Geyser&quot;) else c(&quot;#008585&quot;, &quot;#359087&quot;, &quot;#539B8A&quot;, &quot;#6DA590&quot;, &quot;#85AF97&quot;, &quot;#9BBAA0&quot;, &quot;#AEC4AA&quot;, &quot;#BED0B0&quot;, &quot;#D0DCB5&quot;, &quot;#E5E7BC&quot;, &quot;#FBF2C4&quot;, &quot;#F3E3B2&quot;, &quot;#EDD59F&quot;, &quot;#E7C68C&quot;, &quot;#E3B77A&quot;, &quot;#DEA868&quot;, &quot;#DA9857&quot;, &quot;#D58847&quot;, &quot;#D1773A&quot;, &quot;#CC6530&quot;, &quot;#C7522B&quot;) Plot it: p &lt;- SOmap_auto(x = pr, bathy = pr) p$bathy_palette &lt;- my_cmap p plot(basemap) SOplot(pr, col = my_cmap) 3.7 Other bits and pieces 3.7.1 Place names library(antanym) ## The Composite Gazetteer of Antarctica is made available under a CC-BY license. ## If you use it, please cite it: ## Composite Gazetteer of Antarctica, Scientific Committee on Antarctic Research. GCMD Metadata (http://gcmd.nasa.gov/records/SCAR_Gazetteer.html) ## get full SCAR gazetteer data xn &lt;- an_read(cache = &quot;session&quot;, sp = TRUE) ## Warning: 64974 parsing failures. ## row col expected actual file ## 1018 accepted_by 1/0/T/F/TRUE/FALSE U Harris literal data ## 1018 verified_by 1/0/T/F/TRUE/FALSE U Harris literal data ## 1412 accepted_by 1/0/T/F/TRUE/FALSE AUS literal data ## 2185 verified_by 1/0/T/F/TRUE/FALSE Brolsma literal data ## 2376 scar_feature_class 1/0/T/F/TRUE/FALSE 3 literal data ## .... .................. .................. ........ ............ ## See problems(...) for more details. ## reduce to one name per feature xn &lt;- an_preferred(xn, origin = &quot;United Kingdom&quot;) ## ask for suggestions in our region to show on our map xns &lt;- an_suggest(xn, map_scale = 20e6, map_extent = extent(pr)) ## transform to our map projection, convert to data frame, take the top 10 xns &lt;- as_tibble(SOproj(xns, target = basemap$projection)) %&gt;% head(10) Add them to the map: plot(basemap) SOplot(pr, col = my_cmap, legend = FALSE, breaks = seq(0, 0.9, length.out = length(my_cmap) + 1)) ## curved legend SOleg(position = &quot;bottomleft&quot;, col = my_cmap, breaks = seq(0, 0.9, by = 0.15), type = &quot;continuous&quot;, label = &quot;Probability&quot;) ## placename points with(xns, points(x = longitude, y = latitude, pch = 16, cex = 0.4)) ## and labels with(xns, text(x = longitude, y = latitude, labels = place_name, cex = 0.75, pos = 2 + 2*(seq_len(nrow(xns)) %% 2))) "],
["introduction-to-r-and-the-tidyverse.html", "4 Introduction to R and the Tidyverse 4.1 R", " 4 Introduction to R and the Tidyverse 4.1 R See: The Software Carpentry Introduction to R and RStudio An Introduction to R by the Ocean Biogeographic Information System (OBIS) Getting Started in R — Tidyverse Edition by Saghir Bashir. "],
["occurrences-1.html", "5 Occurrences 5.1 What 5.2 Where 5.3 When 5.4 Who 5.5 How", " 5 Occurrences In general the more information you provide the more knowledge can be gained from your occurrence data. The first user of this data is future yourself. Taking the time to be as detailed in providing and describing your data is time you will gain in the future when you want to reanalyse your data or integrate it in a broader study. The best way is to save the data in some tabular format, something like a csv-file ot Tab delimted txt. It is not recomended to use excel. As this software has the habit of giving you unwanted help, resulting in messed up data… Here we start with a description of the minimal data you should provide in order to analyse your data, including developing a species distribution modeling. Each row in your dataset should corresponding to an observation. The names of the columns in the dataset should correspond to DwC terms. You can find a full description of the Darwincore Terms in the Darwin Core quick reference guide. But below we provide an overview of the most important terms. If you have information that doesn’t ft the Terms below just check the Darwin Core quick reference guide or create an issue on the EG-ABI course github or the [TDWG Github] (https://github.com/tdwg/dwc-qa) your data should allow you or anybody else to determine What, Where, When, Who and How. The Darwincore Standards has 8 absolutely required terms. basisOfRecord, occurrenceID, scientificName, scientificNameID, occurrenceStatus, decimalLongitude, decimalLatitude, eventDate Besides those we recommend a number of other ones as well. In eneral it is better to provide as many as you can. basisOfRecord type associatedReferences occurrenceID institutionCode collectionCode catalogNumber scientificName, scientificNameID scientificNameAuthorship IdentificationQualifier taxonrank occurrenceStatus organismQuantity organismQuantityType sex lifeStage behavior occurrenceRemarks identifiedBy dateIdentified decimalLongitude, decimalLatitude geodeticDatum coordinateUncertaintyInMeters, eventDate year, month, Day, Time, Timezone samplingProtocol 5.1 What 5.1.1 basisOfRecord Additional term type, associatedReferences basisOfRecord describes the nature of record. It has a to follow a specific vocabulary. Some of these might overlap sometimes. That is why it is usefull to use type as well. PreservedSpecimen A specimen that has been preserved. This can be a museum specimen, a plant on an herbarium sheet, fish in a bag in a freezer. FossilSpecimen A resource describing a fossilized specimen. LivingSpecimen A resource describing a living specimen. For instance an animal in a zoo. MaterialSample A resource describing a material sample. For instance Material sample from an organism in the wild and sample put into a collection (blood sample, biopsy). HumanObservation A resource describing an observation made by one or more people. For instance an organism observed in the wild and written in field notes. Samples that were collected during an expedition but thrown back into the sea. MachineObservation An output of a machine observation process. Any kid of automated sensor like camera traps, anipi Occurrence A resource describing an instance of the Occurrence class. NOTE: this value is ambiguous and hence should only be used when the when the resource type is unknown. type The nature or genre of the resource. Must be populated with a value from the DCMI type vocabulary. Options include Image, StillImage, MovingImage, Interactive Resource, PhysicalObject, Sound, Text, PhysicalObject, Collection, Dataset, Event, Service, Software associatedReferences A list (concatenated and separated) of identifiers (publication, bibliographic reference, global unique identifier, URI) of literature associated with the Occurrence. Example: If you want to add a record from literature you should use basisOfRecord:HumanObservation with type:Text in combination with associatedReferences:Bibiographic reference 5.1.2 occurrenceID Additonal Terms institutionCode, collectionCode, catalogNumber occurrenceID is an identifier for the occurrence record and should be globally unique and persistent. In the absence of a persistent global unique identifier, construct one from a combination of identifiers in the record that will most closely make the occurrenceID globally unique. It is recommende to use. Something like the combination of institutionCode, collectionCode, and catalogNumber is a generally used format. There are a number of other terms that you could use as well like datasetName and datasetID institutionCode The name (or acronym) in use by the institution having custody of the object(s) or information referred to in the record. institutionID An identifier for the institution having custody of the object(s) or information referred to in the record. For physical specimens, the recommended best practice is to use a code and identifier from a collections registry such as the Global Registry of Biodiversity Repositories (http://grbio.org/). Institution code Institution name AAS British Antarctic Survey BRM Alfred-Wegener-Institut für Polar- und Meeresforschung MNA The Museo Nazionale dell’Antartide (Italian National Antarctic Museum in Genoa) RBINS Royal Belgian Institute of Natural Sciences collectionCode The name, acronym, coden, or initialism identifying the collection or data set from which the record was derived. datasetName The name identifying the data set from which the record was derived. datasetID An identifier for the set of data. May be a global unique identifier or an identifier specific to a collection or institution. catalogNumber An identifier (preferably unique) for the record within the data set or collection. recordNumber An identifier given to the Occurrence at the time it was recorded. Often serves as a link between field notes and an Occurrence record, such as a specimen collector’s number. occurrenceID institutionCode collectionCode catalogNumber http://arctos.database.museum/guid/MSB:Mamm:233627 MSB Mamm 233627 PS89_FF_000023 PS89 FF 000023 It is a good practice to keep your catalogue/record numbers of equal length throughout your dataset. To keep it persistent just don’t change it. If you reference another source, keep the number. For example if you have samples that were collected during an marine expedition usually all sampling events get ther own ID. Don’t invent a new ID for the event. This will help you to find any information related to that event at a later stage. 5.1.3 scientificName and scientificNameID Additional Terms Kingdom, taxonrank, scientificNameAuthorship, IdentificationQualifier Additional Additional Terms (See Who) identifiedBy, dateIdentified, typeStatus scientificName In the spirit of keeping things persistent this should always contain the originally recorded scientific name, even if the name is currently a synomym (If the sample is reidentified this is of course a different case). The scientific name should always be to the lowest possible taxonomic rank of which you are certain. In case of uncertain identifications, and the scientific name contains qualifiers such as cf., ? or aff., then this name should go in identificationQualifier. scientificNameAuthorship OBIS recommends to not include authorship in scientificName, and only use scientificNameAuthorship for that purpose. scientificNameID Following the OBIS guidelines a WoRMS LSID should be added in scientificNameID, LSIDs are persistent, location-independent, resource identifiers for uniquely naming biologically significant resources. More information on LSIDs can be found at www.lsid.info. taxonrank, Determines the level of idetifciation. This can be for kingdom, phylum,class,order,family,genus,subgenus,specificEpithet,infraspecificEpithet. given that those are terms they can be specified. It is good practisce to always at least provide the Kingdom. In case you can provide a WoRMS LSID the others are not really required. Otherwise it would be good to add them if possible. identificationQualifier A brief phrase or a standard term (“cf.”, “aff.”) to express the determiner’s doubts about the Identification. The use of confer meaning compare and abbeviated to cf. in a scientific name means that the person using the name is saying the animal should be compared to a given species, as it might not be exactly the same species. It’s a way of applying a provisional name to a species and is most frequently used when new fish are discovered that look slightly different to the form normally encountered. It indicates that the fish might be a variant of the same species, but could also turn out to be something completely different. Species affinis (commonly abbreviated to: sp. aff., aff., or affin.) indicates that available material or evidence suggests that the proposed species is related to, has an affinity to, but is not identical to, the species with the binomial name that follows. Species abbreviated as sp. is commonly occurs when authors are confident that some individuals belong to a particular genus but are not sure to which exact species they belong. Authors may also use “spp.” (Species pluralis) as a short way of saying that something applies to many species within a genus, but not to all. scientificName scientificNameAuthorship IdentificationQualifier taxonrank 1 Electrona Goode &amp; Bean, 1896 aff. risso genus 2 Electrona antarctica Günther, 1878 species 3 Electrona Goode &amp; Bean, 1896 sp. genus 4 Electrona Goode &amp; Bean, 1896 spp. genus What are you saying with that? Case 1: “I collected something that looks like Electrona risso but I’m not sure.” Case 2: “I’m 100% sure this is Electrona antarctica) Case 3: “I’m sure about the genus, but it could be any one of multiple species” Case 4: “I have this bag with fish; I’m sure about the genus but it could be a variety of species within the genus” 5.1.4 occurrenceStatus Additional Terms organismQuantity, organismQuantityType, sex, lifeStage, behavior, occurrenceRemarks occurrenceStatus is a statement about the presence or absence of a taxon at a location. It is an important term, because it allows us to distinguish between presence and absence records. It is an OBIS required term and should be filled in with either present or absent. organismQuantity, organismQuantityType These two always go together. organismQuantity is a number for the quantity of animals and organismQuantityType defines the type of quantification system used for the quantity of organisms. organismQuantity organismQuantityType 27 individuals 12.5 %biomass r BraunBlanquetScale There are a few other terms as well that we want to mention. The old term that was used was individualCount but that wasn’t really versatile. Still in some cases it can be usefull to mention it. Please take note that OBIS recommends all quantitative measurements and sampling facts to be treated in the ExtendedMeasurementOrFact extension and not in the Darwin Core files. OBIS recomends using ExtendedMeasurementOrFact in combination with Darwin Core Event Core, which is a little more advanced. sexdecimalLatitude The sex of the biological individual(s) represented in the Occurrence.. The OBIS recommended vocabulary for sex see BODC vocab : S10 lifeStagedecimalLatitude The age class or life stage of the biological individual(s) at the time the Occurrence was recorded. The OBIS recommended vocabulary for lifestage is BODC vocab: S11 behaviordecimalLatitude The behavior shown by the subject at the time the Occurrence was recorded. behavior (no OBIS recomended vocab available) occurrenceRemarksdecimalLatitude can hold any comments or notes about the Occurrence. 5.2 Where 5.2.1 decimalLatitude anddecimalLongitude Additional Terms geodeticDatum, coordinateUncertaintyInMeters, locality, locationID, footprintWKT To determine the location of a point on a globe you need at least the decimalLatitude and decimalLongitude and and a definition of the spatial reference system that was used. The Spatial reference System defines the model of the earts shape that us used. The System currently used by GPS is WGS 84 (also known as WGS 1984, EPSG:4326). Quite often the geodeticDatum is not provided but it is actually essential. decimalLatitude defines the position relative to the equator an ranges from 90° (Norh Pole) to -90 (South Pole) decimalLongitude defines the position relative to the Greenwich Meridian and ranges from 180 to -180. Mak sure not to swith those around. The standard notation has them as Lattitude followed by Longitude. In the decimal notations they are sometimes switched around as this corresponds more to a cartesian notation. Especially for samples collected in the area of the Antarctic peninsula these switches can be hard to spot. coordinateUncertaintyInMeters The horizontal distance (in meters) from the given decimalLatitude and decimalLongitude describing the smallest circle containing the whole of the Location. Leave the value empty if the uncertainty is unknown, cannot be estimated, or is not applicable (because there are no coordinates). Zero is not a valid value for this term. This one is actually closely linked to the number of decimals in your decimalLatitude, decimalLongitude In cases where decimal latitude are calcullated they often get to much digits. If you have more than 6 in biology it doesn’t real make sense anymore or it doesn’t represent how precise the measurement was in the field. To explain it, you can choose this XKCD commic or the table below. decimal places decimal degrees DMS Object that can be unambiguously recognized at this scale N/S or E/W at equator E/W at 67N/S 0 1.0 1° 00’ 0&quot; country or large region 111.32 km 43.496 km 1 0.1 0° 06’ 0&quot; large city or district 11.132 km 4.3496 km 2 0.01 0° 00’ 36&quot; town or village 1.1132 km 434.96 m 3 0.001 0° 00’ 3.6&quot; neighborhood, street 111.32 m 43.496 m 4 0.0001 0° 00’ 0.36&quot; individual street, land parcel 11.132 m 4.3496 m 5 0.00001 0° 00’ 0.036&quot; individual trees, door entrance 1.1132 m 434.96 mm 6 0.000001 0° 00’ 0.0036&quot; individual humans 111.32 mm 43.496 mm 7 0.0000001 0° 00’ 0.00036&quot; practical limit of commercial surveying 11.132 mm 4.3496 mm 8 0.00000001 0° 00’ 0.000036&quot; specialized surveying (e.g. tectonic plate mapping) 1.1132 mm 434.96 µm 5.3 When eventDate Additional Terms year, month, Day, Time, Timezone eventDate The date-time when the occurrence/event was recorded. Can be the date-time or interval during which an Event. This term uses the ISO 8601 standard. OBIS recommends using the extended ISO 8601 format with hyphens. For time intervals ISO 8601 uses / as a separator. Date and time are separated by T. Times can have a time zone indicator at the end, if this is not the case then the time is assumed to be local time. When a time is UTC, a Z is added. Some examples of ISO 8601 dates are: 1973-02-28T15:25:00 2005-08-31T12:11+12 1993-01-26T04:39+12/1993-01-26T05:48+12 2008-04-25T09:53 1948-09-13 1993-01/02 1993-01 1993 It is an option to split out the eventDate into its seperate components. This can be a goood safeguard against software lie excel reformatin your dates and times. year, month, Day, Time, Timezone verbatimEventDate You can put the original date format here, not really needed but might be usefull, in case where you are digitising old literature records. 5.4 Who identifiedBy, dateIdentified identifiedBy A list (concatenated and separated) of names of people, groups, or organizations who assigned the Taxon to the subject. Recommended best practice is to separate the values in a list with space vertical bar space ( | ) dateIdentified This one is very seldom filled out but it is actually an import one and it should be specific, it should be the person that did the actual odentification not the suprvisor. In case of a reindetification at some point it is usefull to contact the person that did the initial identification. 5.5 How samplingProtocol This is a tricky one it is quite relevent but this field often doesn’t provide enough space to describe what you did. For describing a specific gear you can use BODC vocab : L22 "],
["biological-data.html", "6 Biological data 6.1 Taxonomy 6.2 Other packages", " 6 Biological data 6.1 Taxonomy The Register of Antarctic Marine Species (RAMS) is the authoritative taxonomic database for Antarctic marine organisms. RAMS is part of the World Register of Marine Species (WoRMS). worrms client for the WoRMS API. Contains mostly taxonomic data, but also trait data. taxize provides access to 20ish sources of taxonomic data sources, including WoRMS. It has consistent data outputs and function interfaces across the different data sources so that you don’t need to tailor your code to different taxonomic data providers. RAMS is currently being extended to cover non-marine taxa, which will become the Register of Antarctic Species (RAS). Hopefully this will remain covered by worrms and the server-side infrastructure hosted by VLIZ. For more detail on R packages dealing with taxonomy in general, see the rOpenSci taxonomy task view. 6.2 Other packages Tracking of animals using satellite, GPS, or light-level geolocation tags is common, and there are many R packages that can help with this. See the spatiotemporal task view for a more complete list. Also of interest may be: TwilightFree provides a method for processing light-level geolocation data that is robust to noise (sensor shading and obscuration) and may be particularly suitable for Southern Ocean applications. traipse provides tools for tracking data, for common metrics of distance, direction, and speed. foieGras fits a continuous-time model (RW or CRW) in state-space form to filter Argos satellite location data. "],
["environmental-data-1.html", "7 Environmental data 7.1 Bowerbird/blueant 7.2 RAADtools 7.3 Other useful packages", " 7 Environmental data 7.1 Bowerbird/blueant Very commonly, we want to know about the environmental conditions at our points of interest. For the remote and vast Southern Ocean these data typically come from satellite or model sources. Some data centres provide extraction tools that will pull out a subset of data to suit your requirements, but often it makes more sense to cache entire data collections locally first and then work with them from there. bowerbird provides a framework for downloading data files to a local collection, and keeping it up to date. The companion blueant package provides a suite of definitions for Southern Ocean and Antarctic data sources that can be used with bowerbird. It encompasses data such as sea ice, bathymetry and land topography, oceanography, and atmospheric reanalysis and weather predictions, from providers such as NASA, NOAA, Copernicus, NSIDC, and Ifremer. Why might you want to maintain local copies of entire data sets, instead of just fetching subsets of data from providers as needed? many analyses make use of data from a variety of providers (in which case there may not be dynamic extraction tools for all of them), analyses might need to crunch through a whole collection of data in order to calculate appropriate statistics (temperature anomalies with respect to a long-term mean, for example), different parts of the same data set are used in different analyses, in which case making one copy of the whole thing may be easier to manage than having different subsets for different projects, a common suite of data are routinely used by a local research community, in which case it makes more sense to keep a local copy for everyone to use, rather than multiple copies being downloaded by different individuals. In these cases, maintaining local copies of a range of data from third-party providers can be extremely beneficial, especially if that collection is hosted with a fast connection to local compute resources (virtual machines or high-performance computational facilities). Install from GitHub: remotes::install_github(&quot;AustralianAntarcticDivision/blueant&quot;) And load the package before use. library(blueant) 7.1.1 Available data sets First, we can see the available data sets via the sources function. srcs &lt;- blueant::sources() ## the names of the first few head(srcs$name) ## [1] &quot;NSIDC SMMR-SSM/I Nasateam sea ice concentration&quot; ## [2] &quot;NSIDC SMMR-SSM/I Nasateam near-real-time sea ice concentration&quot; ## [3] &quot;NSIDC passive microwave supporting files&quot; ## [4] &quot;Nimbus Ice Edge Points from Nimbus Visible Imagery&quot; ## [5] &quot;Artist AMSR-E sea ice concentration&quot; ## [6] &quot;Artist AMSR-E supporting files&quot; ## the full details of the first one srcs[1, ] ## # A tibble: 1 x 16 ## id name ## &lt;chr&gt; &lt;chr&gt; ## 1 10.5067/8GQ8LZQVL0VL NSIDC SMMR-SSM/I Nasateam sea ice concentration ## description ## &lt;chr&gt; ## 1 &quot;Passive microwave estimates of sea ice concentration at 25km spatial re~ ## doc_url source_url ## &lt;chr&gt; &lt;list&gt; ## 1 http://nsidc.org/data/nsidc-0051.html &lt;chr [1]&gt; ## citation ## &lt;chr&gt; ## 1 Cavalieri, D. J., C. L. Parkinson, P. Gloersen, and H. Zwally. 1996, upd~ ## license ## &lt;chr&gt; ## 1 Please cite, see http://nsidc.org/about/use_copyright.html ## comment ## &lt;chr&gt; ## 1 This data source may migrate to https access in the future, requiring an~ ## method postprocess authentication_note user password ## &lt;list&gt; &lt;list&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; ## 1 &lt;list [5]&gt; &lt;list [0]&gt; &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; ## access_function data_group collection_size ## &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; ## 1 raadtools::readice Sea ice 10 7.1.2 Usage Choose a directory into which to download the data. Usually this would be a persistent directory on your machine so that data sets downloaded in one session would remain available for use in later sessions, and not need re-downloading. A persistent directory could be something like c:\\data\\ (on Windows), or you could use the rappdirs package (the user_cache_dir function) to suggest a suitable directory (cross-platform). Here we’ll use the c:/data/cache directory: my_data_dir &lt;- &quot;/data/cache&quot; Select the data source that we want: data_source &lt;- sources(&quot;Southern Ocean marine environmental data&quot;) Note that it’s a good idea to check the dataset size before downloading it, as some are quite large! (Though if you are running the download interactively, it will ask you before downloading a large data set). data_source$collection_size ## size in GB ## [1] 0.1 And fetch the data: result &lt;- bb_get(data_source, local_file_root = my_data_dir, verbose = TRUE) ## ## Mon Jul 29 17:21:02 2019 ## Synchronizing dataset: Southern Ocean marine environmental data ## Source URL https://data.aad.gov.au/eds/4742/download ## -------------------------------------------------------------------------------------------- ## ## this dataset path is: c:\\data\\cache/data.aad.gov.au/eds/4742 ## building file list ... done. ## downloading file 1 of 1: https://data.aad.gov.au/eds/4742/download ... file unchanged on server, not downloading. ## decompressing: c:\\data\\cache/data.aad.gov.au/eds/4742/download.zip ... no new files to extract (not overwriting existing files) ... done. ## ## Mon Jul 29 17:21:03 2019 dataset synchronization complete: Southern Ocean marine environmental data Now we have a local copy of our data. The sync can be run daily so that the local collection is always up to date - it will only download new files, or files that have changed since the last download. For more information on bowerbird, see the package vignette. The result object holds information about the data that we downloaded: result ## # A tibble: 1 x 5 ## name id ## &lt;chr&gt; &lt;chr&gt; ## 1 Southern Ocean marine environmental data 10.26179/5b8f30e30d4f3 ## source_url status files ## &lt;chr&gt; &lt;lgl&gt; &lt;list&gt; ## 1 https://data.aad.gov.au/eds/4742/download TRUE &lt;tibble [61 x 3]&gt; The result$files element tells us about the files: head(result$files[[1]]) ## # A tibble: 6 x 3 ## url ## &lt;chr&gt; ## 1 https://data.aad.gov.au/eds/4742/download ## 2 &lt;NA&gt; ## 3 &lt;NA&gt; ## 4 &lt;NA&gt; ## 5 &lt;NA&gt; ## 6 &lt;NA&gt; ## file ## &lt;chr&gt; ## 1 &quot;c:\\\\data\\\\cache\\\\data.aad.gov.au\\\\eds\\\\4742\\\\download.zip&quot; ## 2 c:/data/cache/data.aad.gov.au/eds/4742/environmental_layers ## 3 c:/data/cache/data.aad.gov.au/eds/4742/environmental_layers/chla_ampli_a~ ## 4 c:/data/cache/data.aad.gov.au/eds/4742/environmental_layers/chla_max_all~ ## 5 c:/data/cache/data.aad.gov.au/eds/4742/environmental_layers/chla_mean_al~ ## 6 c:/data/cache/data.aad.gov.au/eds/4742/environmental_layers/chla_min_all~ ## note ## &lt;chr&gt; ## 1 existing copy ## 2 decompressed ## 3 decompressed ## 4 decompressed ## 5 decompressed ## 6 decompressed These particular files are netCDF, and so could be read using e.g. the raster or ncdf4 packages. However, different data from different providers will be different in terms of grids, resolutions, projections, variable-naming conventions, and other facets, which tends to complicate these operations. In the next section we’ll look at the raadtools package, which provides a set of tools for doing common operations on these types of data. 7.2 RAADtools The raadtools package provides a consistent interface to a range of environmental and similar data, and tools for working with them. It is designed to work data with collections maintained by the bowerbird/blueant packages, and builds on R’s existing ecosystem of packages for working with spatial, raster, and multidimensional data. Here we’ll use two different environmental data sets: sea ice and water depth. Water depth does not change with time but sea ice is provided at daily time resolution. First download daily sea ice data (from 2013 only), and the ETOPO2 bathymetric data set. ETOPO2 is somewhat dated and low resolution compared to more recent data, but will do as a small dataset for demo purposes. This may take a few minutes, depending on your connection speed: src &lt;- bind_rows( sources(&quot;NSIDC SMMR-SSM/I Nasateam sea ice concentration&quot;, hemisphere = &quot;south&quot;, time_resolutions = &quot;day&quot;, years = 2013), sources(&quot;ETOPO2 bathymetry&quot;)) result &lt;- bb_get(src, local_file_root = my_data_dir, clobber = 0, verbose = TRUE, confirm = NULL) ## ## Mon Jul 29 17:21:03 2019 ## Synchronizing dataset: NSIDC SMMR-SSM/I Nasateam sea ice concentration ## ## [... output truncated] Now load the raadtools package and tell it where our data collection has been stored: library(raadtools) ## Warning in set_raad_filenames(clobber = TRUE): failure to read &#39;//aad.gov.au/files/AADC/Scientific_Data/Data/gridded_new/data/.raad_admin/file_db.rds&#39;: is file corrupt? ## Consider re-running file cache creation. ## Warning in set_raad_filenames(clobber = TRUE): failure to read &#39;//aad.gov.au/files/AADC/Scientific_Data/Data/gridded_new/data_local/.raad_admin/file_db.rds&#39;: is file corrupt? ## Consider re-running file cache creation. ## Uploading raad file cache as at 2019-07-29 17:21:07 (135576 files listed) set_data_roots(my_data_dir) ## Uploading raad file cache as at 2019-07-29 17:21:07 (819 files listed) ## global option &#39;raadfiles.data.roots&#39; set: ## &#39;//aad.gov.au/files/AADC/Scientific_Data/Data/gridded_new/data 2019-07-29 14:51:22 ## //aad.gov.au/files/AADC/Scientific_Data/Data/gridded_new/data_local 2019-07-28 16:39:16 ## //aad.gov.au/files/AADC/Scientific_Data/Data/gridded_new/data_deprecated 2018-09-17 13:42:33&#39; ## global option &#39;raadfiles.data.roots&#39; set: ## &#39;/data/cache 2019-07-19 14:55:38&#39; Let’s say that we have some points of interest in the Southern Ocean — perhaps a ship track, or some stations where we took marine samples, or as we’ll use here, the track of an elephant seal as it moves from the Kerguelen Islands to Antarctica and back again (Data from IMOS 2018[^1], provided as part of the SOmap package). data(&quot;SOmap_data&quot;, package = &quot;SOmap&quot;) ele &lt;- SOmap_data$mirounga_leonina %&gt;% dplyr::filter(id == &quot;ct96-05-13&quot;) Define our spatial region of interest and extract the bathymetry data from this region, using the ETOPO2 files we just downloaded: roi &lt;- round(c(range(ele$lon), range(ele$lat)) + c(-2, 2, -2, 2)) bx &lt;- readtopo(&quot;etopo2&quot;, xylim = roi) And now we can make a simple plot of our our track superimposed on the bathymetry: plot(bx) lines(ele$lon, ele$lat) The real power of raadtools comes from its extraction functions. We can extract the depth values along our track using the extract() function. We pass it the data-reader function to use (readtopo), the data to apply it to (ele[, c(&quot;lon&quot;, &quot;lat&quot;)]), and any other options to pass to the reader function (in this case, specifying the topographic data source topo = &quot;etopo2&quot;): ele$depth &lt;- extract(readtopo, ele[, c(&quot;lon&quot;, &quot;lat&quot;)], topo = &quot;etopo2&quot;) Plot the histogram of depth values, showing that most of the track points are located in relatively shallow waters: with(ele, hist(depth, breaks = 20)) This type of extraction will also work with time-varying data — for example, we can extract the sea-ice conditions along our track, based on each track point’s location and time: ele$ice &lt;- extract(readice, ele[, c(&quot;lon&quot;, &quot;lat&quot;, &quot;date&quot;)]) ## points outside the ice grid will have missing ice values, so fill them with zeros ele$ice[is.na(ele$ice)] &lt;- 0 with(ele, plot(date, ice, type = &quot;l&quot;)) 7.3 Other useful packages the PolarWatch project aims to enable data discovery and broader use of high-latitude ocean remote sensing data sets. The dedicated ERDDAP server (https://polarwatch.noaa.gov/erddap) is accessible to R users with rerddap. rsoi downloads the most up to date Southern Oscillation Index, Oceanic Nino Index, and North Pacific Gyre Oscillation data. satellite reflectance data are a common basis for estimating chlorophyll-a and other phytoplankton parameters at ocean-basin scales. Global products are widely available; however, Southern-Ocean specific algorithms are likely to provide better estimates in these regions. croc implements the Johnson et al. (2013) Southern Ocean algorithm. more broadly, oce provides a wide range of tools for reading, processing, and displaying oceanographic data, including measurements from Argo floats and CTD casts, sectional data, sea-level time series, and coastline and topographic data. fda.oce provides functional data analysis of oceanographic profiles for front detection, water mass identification, unsupervised or supervised classification, model comparison, data calibration, and more. distancetocoast provides “distance to coastline” data for longitude and latitude coordinates. geodist for very fast calculation of geodesic distances. "],
["mapping.html", "8 Mapping 8.1 Maps in R 8.2 SOmap 8.3 Supporting data for maps", " 8 Mapping 8.1 Maps in R The oldest and most core general mapping package in R is the maps package. It has a simple whole-world coastline data set for immediate use. maps::map() The data underlying this live map is available by capturing the output as an actual object. Notice that the coastline for Antarctica does not extend to the south pole, and that parts of Russia that are east of 180 longitude are not in the western part of the map. m &lt;- maps::map(plot = FALSE) lonlat &lt;- cbind(m$x, m$y) plot(lonlat, pch = &quot;+&quot;, cex = 0.4, axes = FALSE) lines(lonlat, col = &quot;dodgerblue&quot;) abline(h = c(-90, 90), v = c(-180, 180)) A very similar and more modern data set is available in the maptools package. data(&quot;wrld_simpl&quot;, package = &quot;maptools&quot;) library(sp) plot(wrld_simpl) This data set aligns exactly to the conventional -180/180 -90/90 extent of the longitude/latitude projection. plot(0, type = &quot;n&quot;, axes = FALSE, xlab = &quot;&quot;, ylab = &quot;&quot;, xlim = c(-180, 180), ylim = c(-90, 90)) rect(xleft = -180, ybottom = -90, xright = 180, ytop = 90, border = &quot;darkred&quot;, lwd = 4, lty = 2) plot(wrld_simpl, add = TRUE) 8.1.1 Exercises How can we find the longitude and latitude ranges of the maps data m and the maptools data wrld_simpl? Can we draw polygons with a fill colour with the maps package? Answer 1: range(m$x, na.rm = TRUE) range(m$y, na.rm = TRUE) also m$range Answer 2: polygon(lonlat, col = &quot;grey&quot;) does not work, and map(mp, fill = TRUE, col = &quot;grey&quot;) does not work, but maps::map(fill = TRUE, col = &quot;grey&quot;) does seem to work. What’s going on? Look at the very south-eastern corner of the map. The “coastline” has been extended to the very south boundary of the available area. plot(0, type = &quot;n&quot;, axes = FALSE, xlab = &quot;&quot;, ylab = &quot;&quot;, xlim = c(-150, 180), ylim = c(-90, -60)) plot(wrld_simpl, add = TRUE, col = &quot;grey&quot;) rect(xleft = -180, ybottom = -90, xright = 180, ytop = 90, border = &quot;darkred&quot;, lwd = 4, lty = 2) maps::map(add = TRUE, col = &quot;dodgerblue&quot;, lwd = 3) When we add the old maps coastline see that it does not extend to 90S and it does not traverse the southern boundary. One reason for this is that if we choose a projection where the east and west edges of the Antarctic coastline meet then we get what looks a fairly clean join. ## scale factor f &lt;- 3e6 plot(rgdal::project(lonlat, &quot;+proj=laea +lat_0=-90 +datum=WGS84&quot;), asp = 1, type = &quot;l&quot;, xlim = c(-1, 1) * f, ylim = c(-1, 1) * f, xlab = &quot;&quot;, ylab = &quot;&quot;) If we try the same with wrld_simpl it’s not as neat. We have a strange “seam” that points exactly to the south pole (our projection is centred on longitude = 0, and latitude = -90. plot(sp::spTransform(wrld_simpl, &quot;+proj=laea +lat_0=-90 +datum=WGS84&quot;), asp = 1, xlim = c(-1, 1) * f, ylim = c(-1, 1) * f, xlab = &quot;&quot;, ylab = &quot;&quot;, lwd = 3) abline(v = 0, h = 0, lty = 2, col = &quot;grey&quot;) 8.1.2 Let’s use the maps data! In m we have the maps data structure, and this looks promising. str(m) ## List of 4 ## $ x : num [1:82403] -69.9 -69.9 -69.9 -70 -70.1 ... ## $ y : num [1:82403] 12.5 12.4 12.4 12.5 12.5 ... ## $ range: num [1:4] -180 190.3 -85.2 83.6 ## $ names: chr [1:1627] &quot;Aruba&quot; &quot;Afghanistan&quot; &quot;Angola&quot; &quot;Angola:Cabinda&quot; ... ## - attr(*, &quot;class&quot;)= chr &quot;map&quot; mp &lt;- m pxy &lt;- rgdal::project(lonlat, &quot;+proj=laea +lat_0=-90 +datum=WGS84&quot;) mp$x &lt;- pxy[,1] mp$y &lt;- pxy[,2] mp$range &lt;- c(range(mp$x,na.rm = TRUE), range(mp$y, na.rm = TRUE)) mp$range ## [1] -12709814 12704237 -12576156 12470787 plot(c(-1, 1) * f, c(-1, 1) * f, type = &quot;n&quot;, asp = 1) maps::map(mp, add = TRUE) ## but it doesn&#39;t take much to go awry plot(c(-1, 1) * f, c(-1, 1) * f, type = &quot;n&quot;, asp = 1) maps::map(mp, add = TRUE, fill = TRUE, col = &quot;grey&quot;) The problem is that the maps database has enough internal structure to join lines correctly, with NA gaps between different connected linestrings, but not enough to draw these things as polygons. A similar problem occurs in the default projection. While wrld_simpl has been extend by placing two dummy coordinates at the east and west versions of the south pole, this data set does not have those. We have to look quite carefully to understand what is happening, but this is wrapping around overlapping itself and so close to the southern bound we barely notice. plot(0, type = &quot;n&quot;, axes = FALSE, xlab = &quot;&quot;, ylab = &quot;&quot;, xlim = c(-180, -110), ylim = c(-90, -60)) rect(xleft = -180, ybottom = -90, xright = 180, ytop = 90, border = &quot;darkred&quot;, lwd = 4, lty = 2) maps::map(add = TRUE,col = &quot;grey&quot;, fill = TRUE) maps::map(col = &quot;grey&quot;, fill = TRUE) mpmerc &lt;- m pxy &lt;- rgdal::project(lonlat, &quot;+proj=merc +datum=WGS84&quot;) mpmerc$x &lt;- pxy[,1] mpmerc$y &lt;- pxy[,2] mpmerc$range &lt;- c(range(mpmerc$x,na.rm = TRUE), range(mpmerc$y, na.rm = TRUE)) mpmerc$range ## [1] -20037508 20037508 -20179524 18351859 ## the catastrophe made a little clearer plot(0, xlim = range(mpmerc$range[1:2]), ylim = c(mpmerc$range[1], 0)) maps::map(mpmerc, fill = TRUE, col = &quot;grey&quot;, add = TRUE) 8.2 SOmap The SOmap package is intended to solve some of these problems, and provide an easier way to produce nice-looking maps of Antarctica and the Southern Ocean. It is primarily focused on maps in polar stereographic projection (although the SOmap_auto function extends this to other projections). SOmap won’t necessarily get you exactly the map you want. But if it doesn’t, it should hopefully get you close enough that you can make modifications to suit your exact purposes. Please bear in mind that SOmap is still in development, and so its functionality (function parameters and/or behaviour) may change. By default, SOmap works with base graphics (and associated functionality from packages such as raster and sp). It is also possible to work with ggplot2-based graphics, as described below. Start by loading the SOmap package: library(SOmap) ## also define a colour map to use for some examples my_cmap &lt;- colorRampPalette(c(&quot;#4D4140&quot;, &quot;#596F7E&quot;, &quot;#168B98&quot;, &quot;#ED5B67&quot;, &quot;#E27766&quot;, &quot;#DAAD50&quot;, &quot;#EAC3A6&quot;))(51) 8.2.1 Circumpolar maps A basic circumpolar map in polar stereographic projection: {r somap1 SOmap() SOmanagement() provides a number of contextual layers such as MPA boundaries and management zones. SOmap(trim = -40) ## plot to 40S ## add the exclusive economic zones management layer SOmanagement(eez = TRUE) 8.2.1.1 Adding points ## some longitude/latitude data library(sp) my_points_ll &lt;- data.frame(lon = seq(0, 350, by = 10), lat = -55, z = runif(36)) coordinates(my_points_ll) &lt;- c(&quot;lon&quot;, &quot;lat&quot;) projection(my_points_ll) &lt;- &quot;+proj=longlat +datum=WGS84&quot; This needs to be reprojected to match our map before plotting. The SOproj function does this: ## reproject to our SOmap projection my_points &lt;- SOproj(my_points_ll) ## and plot SOmap() plot(my_points, col = &quot;blue&quot;, add = TRUE) Or use SOplot to reproject and plot in one step: SOmap() SOplot(my_points_ll, col = &quot;blue&quot;) 8.2.1.2 Adding raster layers First let’s construct some artificial raster data (in longitude-latitude space) for demonstration purposes: library(raster) temp &lt;- as.data.frame(expand.grid(lon = seq(100, 140, by = 0.25), lat = seq(-65, -45, by = 0.1))) temp$val &lt;- sqrt((temp$lon - 120)^2/3 + (temp$lat - -40)^2/5) ## create raster object xr &lt;- rasterFromXYZ(temp) projection(xr) &lt;- &quot;+proj=longlat +datum=WGS84&quot; SOplot will reproject and plot this for us: SOmap() SOplot(xr) The legend is out of character with the rest of the map. We can use SOleg to fix that: ## draw the base map SOmap() ## add our raster SOplot(xr, legend = FALSE, col = my_cmap) ## add the legend SOleg(xr, position = &quot;topright&quot;, col = my_cmap, ticks = 6, type = &quot;continuous&quot;, label = &quot;My variable&quot;) OK, well that worked but clearly the labels need tidying up. We can do that, but we have to be careful to make sure that the colour range of the legend matches that of the plotted raster. ## draw the base map SOmap() ## add our raster, controlling the colour range to span the values 0 to 30 colour_breaks &lt;- seq(0, 30, length.out = length(my_cmap) + 1) SOplot(xr, legend = FALSE, col = my_cmap, breaks = colour_breaks) ## add the legend, again controlling the colour range label_breaks &lt;- seq(0, 30, length.out = 7) SOleg(position = &quot;topright&quot;, col = my_cmap, breaks = label_breaks, type = &quot;continuous&quot;, label = &quot;My variable&quot;) Note that if we don’t want to show the bathymetric legend, we may run into problems: SOmap(bathy_legend = FALSE) ## suppress the bathy legend SOleg(position = &quot;topright&quot;, col = my_cmap, breaks = label_breaks, type = &quot;continuous&quot;, label = &quot;My variable&quot;) The legend has been chopped off because the layout has not left enough space around the map for the curved legend. Currently, the best solution is probably to generate the SOmap object with the bathymetric legend, but then remove it before plotting (see the Modifying map objects section for more details on this): temp &lt;- SOmap() temp$bathy_legend &lt;- NULL ## remove the bathy legend plot(temp) SOleg(position = &quot;topright&quot;, col = my_cmap, breaks = label_breaks, type = &quot;continuous&quot;, label = &quot;My variable&quot;) Multiple rasters: xr2 &lt;- shift(xr, x = -70) ## offset in longitude SOmap() SOplot(xr, legend = FALSE, col = my_cmap) SOplot(xr2, legend = FALSE, col = my_cmap) 8.2.2 Non-circumpolar maps The SOmap_auto function will take your input data and make a guess at an appropriate projection and extent to use. Note that this is not always going to guess the best projection and extent, so you should view it as a starting point from which you can generate a map to your exact requirements. Use the elephant seal track data bundled with the package: ellie &lt;- SOmap_data$mirounga_leonina ## construct and plot the map SOmap_auto(ellie$lon, ellie$lat) Just a blank map to which you could add other things: SOmap_auto(ellie$lon, ellie$lat, input_points = FALSE, input_lines = FALSE) You can pass a raster as input data, but note that it won’t plot the raster (it uses its extent to infer an appropriate extent for the map): SOmap_auto(xr) But we can add the raster if we wish: SOmap_auto(xr) SOplot(xr, col = my_cmap) We can force a particular projection: SOmap_auto(xr, target = &quot;laea&quot;, centre_lon = 147, centre_lat = -42) SOplot(xr, col = my_cmap) Same but by supplying a full proj4 string to target: SOmap_auto(xr, target = &quot;+proj=laea +lat_0=-42 +lon_0=147&quot;) SOplot(xr, col = my_cmap) See the SOmap_auto vignette for more examples. 8.2.3 Plotting via ggplot2 The SOmap and SOmap_auto functions do their plotting using base graphics. If you are more comfortable working with ggplot2, this is also possible. The SOgg function takes an object created by one of those functions (using base graphics) and converts it to use ggplot2 graphics instead. As with other SOmap functions, this returns an object (of class SOmap_gg or SOmap_auto_gg) that contains all of the information needed to generate the map. Printing or plotting this object will cause it to construct a ggplot object. Printing or plotting that object will cause it to be drawn to the graphics device, just like any other ggplot object. myplot &lt;- SOmap() myplotgg &lt;- SOgg(myplot) ## creates a SOmap_gg object class(myplotgg) ## [1] &quot;SOmap_gg&quot; my_ggplot &lt;- plot(myplotgg) ## creates a ggplot object class(my_ggplot) ## [1] &quot;gg&quot; &quot;ggplot&quot; plot(my_ggplot) ## plot it Or in one step (this will cause myplot to be converted to SOmap’s internal gg format, then a ggplot object constructed from that, then that object will be plotted): SOgg(myplot) 8.2.4 Modifying map objects (advanced usage) 8.2.4.1 Modifying base graphics maps Calls to SOmap(), SOmanagement(), SOmap_auto() return an object of class SOmap, SOmap_management, or SOmap_auto. These objects contain all of the data and plotting instructions required to draw the map. Calling print() or plot() on one of these objects will cause that code to be executed, and the object to be drawn in the current graphics device. Hence, calling SOmap() directly without assigning the result to a variable will make it appear in the graphics device, because the returned object is being printed to the console (and thus triggering the print method). But you can also assign the result to a variable, e.g. myplot &lt;- SOmap() and then explicitly plot the object with plot(myplot). The advantage of this is that you can potentially manipulate the myplot object to make changes to the map before plotting it. Note, this is likely to be fragile. Proceed at your own risk! mymap &lt;- SOmap() names(mymap) ## [1] &quot;projection&quot; &quot;target&quot; &quot;straight&quot; &quot;trim&quot; ## [5] &quot;bathy&quot; &quot;box&quot; &quot;plot_sequence&quot; &quot;coastline&quot; ## [9] &quot;ice&quot; &quot;outer_mask&quot; &quot;bathy_legend&quot; &quot;border&quot; The object contains a plot_sequence component, which defines the order in which each part of the plot is drawn. The other components of the object contain the code required to draw each part. Take e.g. the ice component (this is the ice shelves, glacier tongues, etc). This is a list (in this case with only one element). Each element of the list specifies a function to run along with arguments to pass to it: str(mymap$ice) ## List of 1 ## $ :List of 2 ## ..$ plotfun : chr &quot;plot&quot; ## ..$ plotargs:List of 4 ## .. ..$ x :sfc_POLYGON of length 354; first list element: List of 1 ## .. .. ..$ : num [1:5, 1:2] 1022981 1026000 1021994 1021935 1022981 ... ## .. .. ..- attr(*, &quot;class&quot;)= chr [1:3] &quot;XY&quot; &quot;POLYGON&quot; &quot;sfg&quot; ## .. ..$ col : logi NA ## .. ..$ border: chr &quot;black&quot; ## .. ..$ add : logi TRUE ## ..- attr(*, &quot;class&quot;)= chr &quot;SO_plotter&quot; We can modify the function and/or its arguments: mymap$ice[[1]]$plotargs$col &lt;- &quot;green&quot; plot(mymap) We can remove entire components: temp &lt;- mymap temp$coastline &lt;- NULL temp$ice &lt;- NULL plot(temp) But note that some elements are required (in particular, the bathymetry layer can’t currently be removed because the code that draws this is also the code that creates the plot). This code would fail (not run here): temp &lt;- mymap temp$bathy &lt;- NULL plot(temp) However, we could replace the bathymetry data with another raster object. We need to be careful about the extent and projection of this raster. For example, simply replacing the bathymetry raster with the ice raster (which has the same polar stereographic projection but smaller extent) gives: temp &lt;- mymap temp$bathy[[1]]$plotargs$x &lt;- ice temp$bathy_legend &lt;- NULL plot(temp) But if we extend the ice raster to match the map extent: temp &lt;- mymap temp$bathy[[1]]$plotargs$x &lt;- raster::extend(ice, mymap$target) temp$bathy_legend &lt;- NULL plot(temp) 8.2.4.2 Modifying ggplot maps We can modify ggplot2-based maps at two levels. 8.2.4.2.1 Modifying the ggplot object. Remember that printing or plotting a SOmap_gg object produces a ggplot object. This can be modified by adding e.g. layers or themes just like a normal ggplot. Remember to load the ggplot2 library now that we are using ggplot2 functions directly. library(ggplot2) my_ggplot + geom_point(data = as.data.frame(my_points), aes(lon, lat, colour = z), size = 3) + scale_colour_distiller(palette = &quot;Spectral&quot;) Multiple rasters or multiple sets of points gets tricky if they are on different scales, because ggplot2 is only designed to work with a single colour scale per geometry type. You can try your luck with the ggnewscale or relayer packages, although both are in a fairly experimental stage of development. ## remotes::install_github(&quot;clauswilke/relayer&quot;) library(relayer) plot(SOgg(SOmap(straight = TRUE))) + rename_geom_aes(geom_raster(data = as.data.frame(SOproj(xr), xy = TRUE), aes(x = x, y = y, fill2 = val)), new_aes = c(fill = &quot;fill2&quot;)) + scale_fill_gradientn(aesthetics = &quot;fill2&quot;, colors = my_cmap, na.value = NA, name = &quot;My variable&quot;, guide = &quot;legend&quot;) ## remotes::install_github(&quot;eliocamp/ggnewscale&quot;) library(ggnewscale) plot(SOgg(SOmap(straight = TRUE))) + new_scale_fill() + geom_raster(data = as.data.frame(SOproj(xr), xy = TRUE), aes(x = x, y = y, fill = val)) + scale_fill_gradientn(colors = my_cmap, na.value = NA, name = &quot;My variable&quot;) 8.2.4.2.2 Modifying the SOmap_gg object SOmap_gg objects are similar in structure to SOmap objects, in that they contain all of the data and plotting instructions required to draw the map: names(myplotgg) ## [1] &quot;projection&quot; &quot;target&quot; &quot;straight&quot; &quot;trim&quot; ## [5] &quot;init&quot; &quot;bathy&quot; &quot;coord&quot; &quot;plot_sequence&quot; ## [9] &quot;scale_fill&quot; &quot;bathy_legend&quot; &quot;coastline&quot; &quot;ice&quot; ## [13] &quot;axis_labels&quot; &quot;theme&quot; &quot;border&quot; However, instead of base plotting functions, SOmap_gg objects use ggplot2 function calls, e.g.: myplotgg$ice[[1]]$plotfun ## [1] &quot;ggplot2::geom_sf&quot; We can modify these function and/or arguments in a similar manner to SOmap objects. myplotgg$ice[[1]]$plotargs$fill &lt;- &quot;green&quot; plot(myplotgg) Or remove the bathymetric raster layer: temp &lt;- myplotgg temp$bathy &lt;- NULL temp$bathy_legend &lt;- NULL plot(temp) Or replace it with a different raster (use the ice raster as an example): temp &lt;- myplotgg ## convert ice raster to suitable data.frame ice_raster_as_df &lt;- raster::as.data.frame(SOproj(ice), xy = TRUE) names(ice_raster_as_df)[3] &lt;- &quot;ice&quot; ## add this to our object in place of bathy temp$bathy &lt;- SO_plotter(plotfun = &quot;ggplot2::geom_raster&quot;, plotargs = list(data = ice_raster_as_df, mapping = aes_string(fill = &quot;ice&quot;)) ) ## change the colour scale temp$scale_fill[[1]]$plotargs &lt;- list(colours = my_cmap, na.value = &quot;#FFFFFF00&quot;, guide = FALSE) ## remove the bathy legend temp$bathy_legend &lt;- NULL plot(temp) 8.3 Supporting data for maps When constructing maps, we commonly want to show features like oceanographic fronts, ice extent, coastline, place names, and MPA boundaries. There are a few sources of such data: some layers are bundled into SOmap, see the SOmap::SOmap_data object antanym provides access to the SCAR Composite Gazetteer of place names the quantarcticR package provides access to Quantarctica data layers. 8.3.1 quantarcticR Note, this package is still in development, so the usage as shown here might change in later versions. Install if needed: remotes::install_github(&quot;SCAR-sandpit/quantarcticR&quot;) Example usage: library(quantarcticR) ## Quantarctica is made available under a CC-BY license. If you use it, please cite it: ## Matsuoka K, Skoglund A, Roth G (2018) Quantarctica [Data set]. Norwegian Polar Institute. https://doi.org/10.21334/npolar.2018.8516e961 ## In addition, published works produced using Quantarctica are asked to cite each dataset that was used in the work. Please consult the abstract of each data set for the relevant citation. ds &lt;- qa_datasets() ## all available layers head(ds) ## # A tibble: 6 x 5 ## layername ## &lt;chr&gt; ## 1 Overview place names ## 2 COMNAP listed facilities ## 3 Subantarctic stations ## 4 SCAR Composite gazetteer ## 5 IBO-IOC GEBCO Features (point) ## 6 IBO-IOC GEBCO Features (multipoint) ## main_file ## &lt;chr&gt; ## 1 &quot;C:\\\\Users\\\\ben_ray\\\\AppData\\\\Local\\\\Temp\\\\RtmpELLr7i/quantarcticR-cache~ ## 2 &quot;C:\\\\Users\\\\ben_ray\\\\AppData\\\\Local\\\\Temp\\\\RtmpELLr7i/quantarcticR-cache~ ## 3 &quot;C:\\\\Users\\\\ben_ray\\\\AppData\\\\Local\\\\Temp\\\\RtmpELLr7i/quantarcticR-cache~ ## 4 &quot;C:\\\\Users\\\\ben_ray\\\\AppData\\\\Local\\\\Temp\\\\RtmpELLr7i/quantarcticR-cache~ ## 5 &quot;C:\\\\Users\\\\ben_ray\\\\AppData\\\\Local\\\\Temp\\\\RtmpELLr7i/quantarcticR-cache~ ## 6 &quot;C:\\\\Users\\\\ben_ray\\\\AppData\\\\Local\\\\Temp\\\\RtmpELLr7i/quantarcticR-cache~ ## type cached download_size ## &lt;chr&gt; &lt;lgl&gt; &lt;fs::bytes&gt; ## 1 shapefile FALSE 19.74K ## 2 shapefile FALSE 691.92K ## 3 shapefile FALSE 691.92K ## 4 shapefile FALSE 329.05M ## 5 shapefile FALSE 1.25M ## 6 shapefile FALSE 1.25M ## more info about a particular layer my_layer &lt;- qa_dataset(&quot;Median sea ice extent 1981-2010&quot;) my_layer ## # A tibble: 1 x 11 ## layername ## &lt;chr&gt; ## 1 Median sea ice extent 1981-2010 ## datasource ## &lt;chr&gt; ## 1 SeaIce/Median Ice Extents/Median_SeaIce_Extents_1981-2010.shp ## layer_attributes srs_attributes provider ## &lt;list&gt; &lt;list&gt; &lt;chr&gt; ## 1 &lt;NULL&gt; &lt;tibble [1 x 4]&gt; ogr ## abstract ## &lt;chr&gt; ## 1 &quot;Monthly median sea ice extents for the period 1981-2010.\\n\\nFetterer, F~ ## extent type download_size ## &lt;list&gt; &lt;chr&gt; &lt;fs::bytes&gt; ## 1 &lt;NULL&gt; shapefile 131K ## main_file ## &lt;chr&gt; ## 1 &quot;C:\\\\Users\\\\ben_ray\\\\AppData\\\\Local\\\\Temp\\\\RtmpELLr7i/quantarcticR-cache~ ## bb_source$id ## &lt;chr&gt; ## 1 Quantarctica: Median sea ice extent 1981-2010 ## $name $description ## &lt;chr&gt; &lt;chr&gt; ## 1 Median sea ice extent 1981-2010 Quantarctica data ## $doc_url $source_url ## &lt;chr&gt; &lt;list&gt; ## 1 http://quantarctica.npolar.no/ &lt;chr [1]&gt; ## $citation ## &lt;chr&gt; ## 1 Matsuoka, K., Skoglund, A., &amp; Roth, G. (2018). Quantarctica Median sea i~ ## $license $comment $method $postprocess ## &lt;chr&gt; &lt;chr&gt; &lt;list&gt; &lt;list&gt; ## 1 CC-BY 4.0 International &lt;NA&gt; &lt;list [5]&gt; &lt;list [0]&gt; ## $authentication_note $user $password $access_function $data_group ## &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; ## 1 &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; ## $collection_size ## &lt;lgl&gt; ## 1 NA ## fetch the actual data for that layer layer_data &lt;- qa_get(my_layer) ## plot it plot(layer_data[layer_data$MONTH == &quot;October&quot;, ]) ## or add to a SOmap SOmap(trim = -50, border_width = 0.5) SOplot(layer_data[layer_data$MONTH == &quot;October&quot;, ], col = &quot;red&quot;) 8.3.2 antanym See the overview article. "],
["species-distribution-modelling.html", "9 Species distribution modelling 9.1 Introduction and review 9.2 Methods 9.3 Evaluation", " 9 Species distribution modelling 9.1 Introduction and review 9.2 Methods 9.3 Evaluation 9.3.1 Other modelling approaches "],
["other-r-resources-for-southern-oceanantarctic-use.html", "10 Other R resources for Southern Ocean/Antarctic use 10.1 Diet data: sohungry 10.2 Allometric equations: solong", " 10 Other R resources for Southern Ocean/Antarctic use 10.1 Diet data: sohungry The sohungry package provides access to data from the SCAR Southern Ocean Diet and Energetics Database, and some tools for working with these data. The database includes data related to diet and energy flow from conventional (e.g. gut content) and modern (e.g. molecular) studies, stable isotopes, fatty acids, and energetic content. It is a product of the SCAR community and open for all to participate in and use. See the sohungry package vignette for more information. 10.2 Allometric equations: solong The solong package provides allometric equations that relate the body size of Southern Ocean taxa to their body part measurements. It is a component of the Southern Ocean Diet and Energetics Database project. See the package reference. "]
]
